{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AyudantÃ­a 5 MÃ©todos iterativos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Programe los mÃ©todos de SOR, Jacobi, Gauss-Seidel y Richardson. Compare las implementaciones por entrada versus matricial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussSeidel(A,b,xstart,tol=1e-5): # A = L + D + E \n",
    "    print(\"Gauss Seidel\")\n",
    "    x = xstart.copy()\n",
    "    L = np.tril(A)\n",
    "    U = A - L\n",
    "    while abs(A@x-b).max() > tol:\n",
    "        x = np.linalg.inv(L)@(b-U@x)\n",
    "    print(\"Residual norm\",np.linalg.norm(A@x-b))\n",
    "    return x\n",
    "        \n",
    "def SOR(A,b,xstart,w,tol=1e-5):\n",
    "    print(\"SOR\")\n",
    "    x = xstart.copy()\n",
    "    D = np.eye(A.shape[0])*A\n",
    "    L = np.tril(A-D)\n",
    "    U = np.triu(A-D)\n",
    "    while abs(A@x-b).max() > tol:\n",
    "        x = np.linalg.inv(D+w*L) @ ((1-w)*D@x-w*U@x+w*b)\n",
    "    print(\"Residual norm\",np.linalg.norm(A@x-b))\n",
    "    return x\n",
    "\n",
    "def Jacobi(A,b,xstart,tol=1e-5):\n",
    "    print(\"Jacobi\")\n",
    "    x = xstart.copy()\n",
    "    D = np.eye(A.shape[0])*A\n",
    "    L = np.tril(A-D)\n",
    "    U = np.triu(A-D)\n",
    "    while abs(A@x-b).max() > tol:\n",
    "        x_new = np.linalg.inv(D)@(b-(L+U)@x)\n",
    "        x = x_new.copy()\n",
    "    print(\"Residual norm\",np.linalg.norm(A@x-b))\n",
    "    return x\n",
    "\n",
    "def Richardson(A,b,xstart,w,tol=1e-5):\n",
    "    \"\"\"inf 0.5*||Ax-b||^2 x \"\"\"\n",
    "    \"\"\" Looks a lot like gradient descent \"\"\"\n",
    "    print(\"Richardson\")\n",
    "    x = xstart.copy()\n",
    "    while abs(A@x-b).max() > tol:\n",
    "        x = x + w*(b-A@x) ## line search\n",
    "    print(\"Residual norm\",np.linalg.norm(A@x-b))\n",
    "    return x\n",
    "def gradient_descent_exact_line_search(A,b,xstart,tol=1e-5):\n",
    "    print(\"Gradient descent\")\n",
    "    x = xstart.copy()\n",
    "    while abs(A@x-b).max() > tol:\n",
    "        g_c = A@x-b\n",
    "        mu = np.dot(g_c,g_c)/np.dot(g_c,A@g_c)\n",
    "        x = x - mu*(A@x-b)\n",
    "    print(\"Residual norm\",np.linalg.norm(A@x-b))\n",
    "    return x\n",
    "# w_sor = 2/(1 + np.sqrt((2*(1-rhoJ))))\n",
    "def SSOR(A, w):\n",
    "    D = np.diag(A.diagonal())\n",
    "    Dm1 = np.diag(1/A.diagonal())\n",
    "    L = np.tril(A, k=-1)\n",
    "    M = (w/(2-w))*((1/w)*D + L) @ Dm1 @ ((1/w)*D + L).T\n",
    "    N = M-A\n",
    "    return M, N # noten que aquÃ­ se arman las matrices, queda para uds implementar la iteraciÃ³n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nadie le gusta invertir matrices!ðŸ¤®ðŸ¤®ðŸ¤®ðŸ¤§ðŸ¤§ðŸ¤§ðŸ¤¯ðŸ¤¯ðŸ¤¯ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pruebe los mÃ©todos de 1. con la matriz de diferencias finitas e implemente una versiÃ³n mÃ¡s eficiente para el problema particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15\n",
    "test_1D = np.diag(np.ones(n)*2) + np.diag(np.ones(n-1)*-1,1) + np.diag(np.ones(n-1)*-1,-1)\n",
    "test_2D = np.kron(test_1D,np.eye(n)) + np.kron(np.eye(n),test_1D)\n",
    "# Define the \"true solution\"\n",
    "x_true_1D = np.random.rand(n)\n",
    "x_true_2D = np.random.rand(n**2)\n",
    "# Get the right hand side\n",
    "b_1D = test_1D@x_true_1D\n",
    "b_2D = test_2D@x_true_2D\n",
    "# Initial guess\n",
    "xstart_1D = np.ones(n)\n",
    "xstart_2D = np.ones(n**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gauss Seidel\n",
      "Residual norm 2.7692996173405286e-05\n",
      "SOR\n",
      "Residual norm 2.3827875011993093e-05\n",
      "Jacobi\n",
      "Residual norm 2.5763690558533927e-05\n",
      "Richardson\n",
      "Residual norm 2.8274198017857964e-05\n",
      "Gradient descent\n",
      "Residual norm 2.0219727838028566e-05\n",
      "Time testing 1D 0.13443708419799805 s\n",
      "Gauss Seidel\n",
      "Residual norm 7.908501461849297e-05\n",
      "SOR\n",
      "Residual norm 7.496311984648916e-05\n",
      "Jacobi\n",
      "Residual norm 6.540292628660751e-05\n",
      "Richardson\n",
      "Residual norm 7.940773788643053e-05\n",
      "SSOR\n",
      "Did not converge\n",
      "Residual norm 276.7151932602389\n",
      "Time testing 2D 10.483360052108765 s\n"
     ]
    }
   ],
   "source": [
    "# Solve the system 1D tests\n",
    "t1 = time.time()\n",
    "x_1D_GS = GaussSeidel(test_1D,b_1D,xstart_1D)\n",
    "x_1D_SOR = SOR(test_1D,b_1D,xstart_1D,1.5)\n",
    "x_1D_Jacobi = Jacobi(test_1D,b_1D,xstart_1D)\n",
    "x_1D_Richardson = Richardson(test_1D,b_1D,xstart_1D,0.1)\n",
    "x_1D_gradient = gradient_descent_exact_line_search(test_1D,b_1D,xstart_1D)\n",
    "# x_1D_SSOR = SSOR(test_1D,b_1D,xstart_1D,1.5)\n",
    "t2 = time.time()\n",
    "print(\"Time testing 1D\",t2-t1, \"s\")\n",
    "# SSOR is useful as a preconditioner, not as a solver!\n",
    "\n",
    "# Solve the system 2D tests\n",
    "t1 = time.time()\n",
    "x_2D_GS = GaussSeidel(test_2D,b_2D,xstart_2D)\n",
    "x_2D_SOR = SOR(test_2D,b_2D,xstart_2D,1.5)\n",
    "x_2D_Jacobi = Jacobi(test_2D,b_2D,xstart_2D)\n",
    "x_2D_Richardson = Richardson(test_2D,b_2D,xstart_2D,0.1)\n",
    "x_2D_SSOR = SSOR(test_2D,b_2D,xstart_2D,1.5)\n",
    "t2 = time.time()\n",
    "print(\"Time testing 2D\",t2-t1, \"s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not AS naive implementation\n",
    "# Refer to https://sites.pitt.edu/~sts106/MEMS1055_Project_1.pdf\n",
    "\n",
    "def GaussSeidel_byrow(A,b,xstart,tol=1e-5):\n",
    "    print(\"Gauss Seidel by row\")\n",
    "    x = xstart.copy()\n",
    "    A_aux = A - np.eye(A.shape[0])*A \n",
    "    while abs(A@x-b).max() > tol:\n",
    "        for i in range(A.shape[0]):\n",
    "            x[i] = (1/A[i,i]) * (b[i] - np.dot(A_aux[i], x)) # np.sum([A_aux[i,j]*x[j] for j in range(A.shape[0])\n",
    "    print(\"Residual norm\",np.linalg.norm(A@x-b))\n",
    "    return x\n",
    "def Jacobi_byrow(A,b,xstart,tol=1e-5): \n",
    "    print(\"Jacobi by row\")\n",
    "    x = xstart.copy()\n",
    "    D = np.eye(A.shape[0])*A\n",
    "    A_aux = A - D\n",
    "    while abs(A@x-b).max() > tol:\n",
    "        x_new = np.zeros_like(x)\n",
    "        for i in range(A.shape[0]):\n",
    "            x_new[i] = (1/A[i,i]) * (b[i] - np.dot((A_aux)[:,i],x)) \n",
    "        x = x_new.copy()\n",
    "    print(\"Residual norm\",np.linalg.norm(A@x-b))\n",
    "    return x\n",
    "\n",
    "def SOR_byrow(A,b,xstart,w,tol=1e-5):\n",
    "    print(\"SOR by row\")\n",
    "    x = xstart.copy()\n",
    "    A_aux = A - np.eye(A.shape[0])*A\n",
    "    while abs(A@x-b).max() > tol:\n",
    "        for i in range(A.shape[0]):\n",
    "            x[i] = (1-w)*x[i] + w/A[i,i]*(b[i]- np.dot(A_aux[i], x)) #room for improvement\n",
    "    print(\"Residual norm\",np.linalg.norm(A@x-b))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gauss Seidel by row\n",
      "Residual norm 2.7692996173442806e-05\n",
      "SOR by row\n",
      "Residual norm 2.3827875011993567e-05\n",
      "Jacobi by row\n",
      "Residual norm 2.5763690558533927e-05\n",
      "Time testing 1D by row 0.018182754516601562 s\n",
      "Gauss Seidel by row\n",
      "Residual norm 7.908501461865292e-05\n",
      "SOR by row\n",
      "Residual norm 7.496311984612386e-05\n",
      "Jacobi by row\n",
      "Residual norm 6.54029262904003e-05\n",
      "Time testing 2D by row 0.32709622383117676 s\n"
     ]
    }
   ],
   "source": [
    "#test new implementation\n",
    "t1 = time.time()\n",
    "x_1D_GS = GaussSeidel_byrow(test_1D,b_1D,xstart_1D)\n",
    "x_1D_SOR = SOR_byrow(test_1D,b_1D,xstart_1D,1.5)\n",
    "x_1D_Jacobi = Jacobi_byrow(test_1D,b_1D,xstart_1D)\n",
    "t2 = time.time()\n",
    "print(\"Time testing 1D by row\",t2-t1, \"s\")\n",
    "\n",
    "t1 = time.time()\n",
    "x_2D_GS = GaussSeidel_byrow(test_2D,b_2D,xstart_2D)\n",
    "x_2D_SOR = SOR_byrow(test_2D,b_2D,xstart_2D,1.5)\n",
    "x_2D_Jacobi = Jacobi_byrow(test_2D,b_2D,xstart_2D)\n",
    "t2 = time.time()\n",
    "print(\"Time testing 2D by row\",t2-t1, \"s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gauss Seidel by row\n",
      "Residual norm 2.7692996173442806e-05\n",
      "Jacobi by row\n",
      "Residual norm 2.5763690558533927e-05\n",
      "SOR by row\n",
      "Residual norm 2.3827875011993567e-05\n",
      "Time testing 1D by row 0.024434328079223633 s\n",
      "Gauss Seidel by row\n",
      "Residual norm 7.908501461865292e-05\n",
      "Jacobi by row\n",
      "Residual norm 6.54029262904003e-05\n",
      "SOR by row\n",
      "Residual norm 7.496311984612386e-05\n",
      "Time testing 2D by row 0.33122873306274414 s\n"
     ]
    }
   ],
   "source": [
    "# test new implementations!!!!\n",
    "t1 = time.time()\n",
    "x_1D_GS = GaussSeidel_byrow(test_1D,b_1D,xstart_1D)\n",
    "x_1D_Jacobi = Jacobi_byrow(test_1D,b_1D,xstart_1D)\n",
    "x_1D_SOR = SOR_byrow(test_1D,b_1D,xstart_1D,1.5)\n",
    "t2 = time.time()\n",
    "print(\"Time testing 1D by row\",t2-t1, \"s\")\n",
    "t1 = time.time()\n",
    "x_2D_GS = GaussSeidel_byrow(test_2D,b_2D,xstart_2D)\n",
    "x_2D_Jacobi = Jacobi_byrow(test_2D,b_2D,xstart_2D)\n",
    "x_2D_SOR = SOR_byrow(test_2D,b_2D,xstart_2D,1.5)\n",
    "t2 = time.time()\n",
    "print(\"Time testing 2D by row\",t2-t1, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img.jpg\" alt=\"??????\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surely can be faster tho..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def SOR_finite_dif_1D(A,b,xstart,w,tol=1e-5):\n",
    "    x = xstart.copy()\n",
    "    A_aux = A - np.eye(A.shape[0])*A\n",
    "    while abs(A@x-b).max() > tol:\n",
    "        for i in range(A.shape[0]):\n",
    "            if i != 0 and i != A.shape[0]-1:\n",
    "                x[i] = (1-w)*x[i] + w/A[i,i]*(b[i]- (-1*x[i-1] -1*x[i+1])) \n",
    "                continue\n",
    "            elif i == 0:\n",
    "                x[i] = (1-w)*x[i] + w/A[i,i]*(b[i]- (-1*x[1]))\n",
    "            elif i == A.shape[0]-1:\n",
    "                x[i] = (1-w)*x[i] + w/A[i,i]*(b[i]- (-1*x[A.shape[0]-2]))\n",
    "            \n",
    "    print(\"Residual norm\",np.linalg.norm(A@x-b))\n",
    "    return x\n",
    "def jacobi_finite_dif_1D(A,b,xstart,tol=1e-5):\n",
    "\n",
    "    x = xstart.copy()\n",
    "    D = np.eye(A.shape[0])*A\n",
    "    A_aux = A - D\n",
    "    while abs(A@x-b).max() > tol:\n",
    "        x_new = np.zeros_like(x)\n",
    "        for i in range(A.shape[0]):\n",
    "            if i != 0 and i != A.shape[0]-1:\n",
    "                x_new[i] = (1/A[i,i]) * (b[i] - (-1*x[i-1] -1*x[i+1]))\n",
    "                continue\n",
    "            elif i == 0:\n",
    "                x_new[i] = (1/A[i,i]) * (b[i] - (-1*x[1])) # why does this work??\n",
    "            elif i == A.shape[0]-1:\n",
    "                x_new[i] = (1/A[i,i]) * (b[i] - (-1*x[A.shape[0]-2]))\n",
    "        x = x_new.copy()\n",
    "            \n",
    "    print(\"Residual norm\",np.linalg.norm(A@x-b))\n",
    "    return x\n",
    "def GaussSeidel_finite_dif_1D(A,b,xstart,tol=1e-5):\n",
    "    \n",
    "    x = xstart.copy()\n",
    "    A_aux = A - np.eye(A.shape[0])*A\n",
    "    while abs(A@x-b).max() > tol:\n",
    "        \n",
    "        for i in range(A.shape[0]):\n",
    "            if i != 0 and i != A.shape[0]-1:\n",
    "                x[i] = (1/A[i,i]) * (b[i] - (-1*x[i-1] -1*x[i+1]) )\n",
    "                continue\n",
    "            elif i == 0:\n",
    "                x[i] = (1/A[i,i]) * (b[i] - (-1*x[1])) \n",
    "            elif i == A.shape[0]-1:\n",
    "                x[i] = (1/A[i,i]) * (b[i] - (-1*x[A.shape[0]-2]))\n",
    "    print(\"Residual norm\",np.linalg.norm(A@x-b))\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big n 1D super naive, not as naive and specially made for the problem side by side\n",
    "n = 200\n",
    "test_1D = np.diag(np.ones(n)*2) + np.diag(np.ones(n-1)*-1,1) + np.diag(np.ones(n-1)*-1,-1)\n",
    "b_1D = np.random.rand(n)\n",
    "xstart_1D = np.ones(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing naive\n",
      "Gauss Seidel\n",
      "Residual norm 0.00010024609998168708\n",
      "SOR\n",
      "Residual norm 0.00010020743347058732\n",
      "Jacobi\n",
      "Residual norm 0.00010020280307993888\n",
      "Time testing 1D naive 149.85855388641357 s\n",
      "\n",
      "Testing not as naive\n",
      "Gauss Seidel by row\n",
      "Residual norm 0.00010024609960032224\n",
      "Jacobi by row\n",
      "Residual norm 0.00010020280307993888\n",
      "SOR by row\n",
      "Residual norm 0.00010020743345076767\n",
      "Time testing 1D not as naive 36.68470501899719 s\n",
      "\n",
      "Testing specially made for the problem\n",
      "Residual norm 0.00010020743345076767\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'jacobian_finite_dif_1D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     19\u001b[0m x_1D_SOR \u001b[39m=\u001b[39m SOR_finite_dif_1D(test_1D,b_1D,xstart_1D,\u001b[39m1.5\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m x_1D_Jacobi \u001b[39m=\u001b[39m jacobian_finite_dif_1D(test_1D,b_1D,xstart_1D)\n\u001b[1;32m     21\u001b[0m x_1D_GS \u001b[39m=\u001b[39m GaussSeidel_finite_dif_1D(test_1D,b_1D,xstart_1D)\n\u001b[1;32m     22\u001b[0m t2 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jacobian_finite_dif_1D' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Testing naive\")\n",
    "t1 = time.time()\n",
    "x_1D_GS = GaussSeidel(test_1D,b_1D,xstart_1D)\n",
    "x_1D_SOR = SOR(test_1D,b_1D,xstart_1D,1.5)\n",
    "x_1D_Jacobi = Jacobi(test_1D,b_1D,xstart_1D)\n",
    "t2 = time.time()\n",
    "print(\"Time testing 1D naive\",t2-t1, \"s\")\n",
    "print()\n",
    "print(\"Testing not as naive\")\n",
    "t1 = time.time()\n",
    "x_1D_GS = GaussSeidel_byrow(test_1D,b_1D,xstart_1D)\n",
    "x_1D_Jacobi = Jacobi_byrow(test_1D,b_1D,xstart_1D)\n",
    "x_1D_SOR = SOR_byrow(test_1D,b_1D,xstart_1D,1.5)\n",
    "t2 = time.time()\n",
    "print(\"Time testing 1D not as naive\",t2-t1, \"s\")\n",
    "print()\n",
    "print(\"Testing specially made for the problem\")\n",
    "t1 = time.time()\n",
    "x_1D_SOR = SOR_finite_dif_1D(test_1D,b_1D,xstart_1D,1.5)\n",
    "x_1D_Jacobi = jacobian_finite_dif_1D(test_1D,b_1D,xstart_1D)\n",
    "x_1D_GS = GaussSeidel_finite_dif_1D(test_1D,b_1D,xstart_1D)\n",
    "t2 = time.time()\n",
    "print(\"Time testing 1D specially made\",t2-t1, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img2.jpeg\" alt=\"??????\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
